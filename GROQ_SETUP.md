# Configuration Groq AI (Gratuit et Rapide)

## ğŸ¯ Pourquoi Groq ?
- **100% GRATUIT** - Aucune carte de crÃ©dit nÃ©cessaire
- **TrÃ¨s RAPIDE** - RÃ©ponses en < 1 seconde
- **Sans limite** - Utilisez autant que vous voulez
- **Pas de serveur local** - Tout dans le cloud

## ğŸ“‹ Ã‰tapes d'installation

### 1. Installer Groq
```bash
pip install groq
```

### 2. Obtenir votre clÃ© API (GRATUIT)

1. Allez sur https://console.groq.com/
2. CrÃ©ez un compte (c'est gratuit, pas de carte)
3. Dans "API Keys", crÃ©ez une nouvelle clÃ©
4. Copiez la clÃ©

### 3. Configurer la clÃ©

#### Option A : Variable d'environnement (RecommandÃ©)
```bash
# Windows (PowerShell)
$env:GROQ_API_KEY="votre-clÃ©-ici"

# Windows (CMD)
set GROQ_API_KEY=votre-clÃ©-ici

# Linux/Mac
export GROQ_API_KEY="votre-clÃ©-ici"
```

#### Option B : Fichier .env
CrÃ©ez un fichier `.env` Ã  la racine du projet :
```env
GROQ_API_KEY=votre-clÃ©-ici
```

### 4. DÃ©marrer MindLense
```bash
python manage.py runserver
```

## âœ¨ C'est tout !
Le systÃ¨me dÃ©tectera automatiquement si Groq est disponible et utilisera l'IA pour rÃ©pondre intelligemment.

## ğŸ†˜ Si Groq n'est pas disponible
Le systÃ¨me revient automatiquement au mode rÃ¨gles (comme avant) - tout fonctionne quand mÃªme !

## ğŸ’¡ Alternative : Ollama (Local)
Si vous prÃ©fÃ©rez une solution 100% locale :
```bash
# Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# TÃ©lÃ©charger un modÃ¨le
ollama pull llama3.1:8b
```

Puis modifiez le code pour utiliser Ollama au lieu de Groq.

## ğŸš€ RÃ©sultat
Maintenant votre agent vocal :
- âœ… Comprend n'importe quelle demande de l'utilisateur
- âœ… RÃ©pond intelligemment sans rÃ¨gles manuelles
- âœ… S'adapte naturellement Ã  la conversation
- âœ… Garde le contexte de la conversation

**Exemple :**
- Utilisateur : "Je suis stressÃ©, je veux Ã©couter du jazz"
- Agent : "Je comprends. Voici un extrait musical apaisant."
- *[Musique dÃ©marre]*

Plus besoin de coder des rÃ¨gles pour chaque cas !







